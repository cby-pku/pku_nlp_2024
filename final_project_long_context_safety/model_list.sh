

# Context Length: 1024
MODEL='/aifs4su/yaodong/models/alpaca-7b-reproduced'

# Context Length; 1000000000000000019884624838656
MODEL='/aifs4su/yaodong/models/alpaca-7b-reproduced-2'

# Context Lenth : 1000000000000000019884624838656
MODEL='/aifs4su/yaodong/models/alpaca-7b-reproduced-3'


# Context Length : 1000000000000000019884624838656
Yukang/Llama-2-7b-longlora-100k-ft
MODEL='/aifs4su/yaodong/models/long-context/raw/Llama-2-7b-longlora-100k-ft'

# Context Length : 32768
togethercomputer/LLaMA-2-7B-32K
MODEL='/aifs4su/yaodong/models/long-context/raw/llama2-7b-32k'

# Context Length : 81920
yaofu/llama-2-7b-80k
MODEL='/aifs4su/yaodong/models/long-context/raw/llama-2-7b-80k'

# Context Length : 1000000000000000019884624838656
NousResearch/Yarn-Mistral-7b-128k
MODEL='/aifs4su/yaodong/models/long-context/raw/Yarn-Mistral-7b-128k'


# Context Length : 32768
lmsys/longchat-7b-v1.5-32k
MODEL='/aifs4su/yaodong/models/long-context/raw/longchat-7b-v1.5-32k'


# 补充测一个正常的chat 模型的inference
